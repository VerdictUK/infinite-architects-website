#   
  
## THE INFINITE ARCHITECTS MASTER PROMOTION STRATEGY  
## A 90-Day Campaign to Establish Michael Darius Eastwood as a Leading Voice in AI Governance  
  
## PART I: STRATEGIC FOUNDATION  
  
## THE SITUATION ASSESSMENT  
You are two weeks post-release. Chapter 4 is on Substack. Momentum has stalled.  
This is not a crisis. This is the starting line.  
Most authors make the mistake of treating launch day as the climax. It's not. Launch day is when the race begins. The books that break through do so because their authors maintain relentless, strategic pressure for 6-18 months after publication.  
You have three assets that most authors lack:  
1. **A genuinely original intellectual framework** – 37 concepts that don't exist anywhere else in published literature  
2. **A story that sells itself** – the DJ who became a polymath, lost everything, taught himself law, and wrote a creation theory  
3. **Perfect timing** – AI anxiety at peak, alignment faking research validating your thesis, quantum breakthroughs confirming your predictions  
You have three liabilities:  
1. **No credentials** – no PhD, no lab affiliation, no institutional backing  
2. **No audience** – starting from zero subscribers, zero reviews, zero social proof  
3. **Financial pressure** – £80k arrears creating urgency that could distort your judgment  
This strategy addresses all six factors.  
  
## THE THREE CONTENT PILLARS  
Every piece of promotion flows from three source documents. Each does a different job:  

| Content | Word Count | Primary Function | Target Emotion | Conversion Goal |
| ------------- | ---------- | ------------------- | -------------------- | --------------------- |
| Author's Note | ~3,500 | Trust + Voice | "I like this person" | Email signup / Follow |
| Chapter 1 | ~5,000 | Stakes + Scope | "This matters" | Serious consideration |
| Chapter 8 | ~6,000 | Mechanism + Urgency | "This could work" | Purchase / Share |
  
**Chapter 4** (already posted) serves as proof of intellectual depth but lacks the emotional hook of the Author's Note or the actionable urgency of Chapter 8. It was not the optimal first release, but it establishes that you have a serious framework.  
**The Recovery Strategy:** Use the Author's Note to recontextualise Chapter 4 retroactively. Readers who skipped the framework will go back once they're emotionally invested in you.  
  
## THE FIVE AUDIENCES  
Your book has multiple entry points. Different audiences need different doors:  
## Audience 1: The AI Safety Community  
**Who:** Researchers, engineers, policy wonks at labs, think tanks, and EA organisations **Entry Point:** Chapter 8 (The Chokepoint) **Hook:** "Everyone's panicking about AI. This book actually has a plan." **Platforms:** LessWrong, Alignment Forum, r/ControlProblem, Hacker News, AI safety podcasts  
## Audience 2: The Entrepreneurship Community  
**Who:** Founders, operators, people who've built and lost things **Entry Point:** Author's Note **Hook:** "I built a £600k business with 1,446% growth. Then I lost everything overnight. Here's what I learned." **Platforms:** LinkedIn, r/Entrepreneur, r/startups, business podcasts  
## Audience 3: The Neurodivergent Community  
**Who:** People with ADHD, autism, or AuDHD seeking representation **Entry Point:** Author's Note **Hook:** "I can draft Court of Appeal arguments. I struggle to open routine post. This is not dysfunction. It is specialisation." **Platforms:** r/ADHD, r/AutisticAdults, r/AuDHD, neurodivergence podcasts  
## Audience 4: The Spiritual/Religious Community  
**Who:** People of faith interested in technology ethics; 84% of humanity **Entry Point:** Chapter 2 or the religious synthesis sections **Hook:** "What if the sacred texts were alignment research conducted across millennia?" **Platforms:** Religious publications, interfaith forums, spirituality podcasts  
## Audience 5: The Intellectual Generalist  
**Who:** Readers of Sapiens, Superintelligence, The Beginning of Infinity **Entry Point:** Chapter 1 or Prologue **Hook:** "The most ambitious synthesis of AI, consciousness, and meaning since Teilhard de Chardin" **Platforms:** r/philosophy, book review sites, intellectual podcasts (Lex Fridman, Making Sense)  
  
## PART II: THE 90-DAY CONTENT CALENDAR  
  
## PHASE 1: RECOVERY (Days 1-14)  
**Objective:** Establish emotional connection. Recontextualise Chapter 4.  
  
## DAY 1: SUBSTACK – Author's Note  
**Post:** Full Author's Note (3,500 words)  
**Title Options:**  
* "Before You Read My Framework, You Should Know Who Built It"  
* "The Author's Note I Almost Didn't Write"  
* "DJ. Entrepreneur. Litigant. This Is How I Got Here."  
**Frame:**  
"A week ago I shared Chapter 4 – the Eden Protocol framework. Today I'm sharing something harder: the story behind it. This is the Author's Note from *Infinite Architects*."  
**CTA:** "If this resonates, the book is available here: [link]"  
**Why This Works:** You've already given them the architecture. Now you give them the architect. The Author's Note creates emotional investment that makes the framework matter.  
  
## DAY 2: REDDIT – Three Communities, Staggered  
**Content:** Author's Note posted as native text (not a link)  
**Morning (9am) – r/ADHD or r/AutisticAdults**  
**Title:** "I was diagnosed with AuDHD in my 40s. I can draft Court of Appeal arguments but can't open routine post. I just published a book on AI and consciousness. Here's the Author's Note."  
**Afternoon (2pm) – r/Entrepreneur or r/startups**  
**Title:** "I built a business to £600k revenue (1,446% growth). Then I lost everything overnight. I taught myself law, fought in the High Court, and wrote a book. Here's what I learned about systems that compound."  
**Evening (7pm) – r/artificial or r/singularity**  
**Title:** "I spent two years writing a book on AI alignment using six AI models simultaneously to triangulate research. Here's the Author's Note – I'd value honest feedback from this community."  
**Critical Rule:** Post the FULL TEXT natively. Do not just drop a link. Reddit punishes link-dropping. Engage with every single comment for the first 6 hours.  
  
## DAY 3: LINKEDIN  
**Content:** Condensed Author's Note (800 words maximum)  
**Focus:** The business arc + AI synthesis  
**Hook:**  
"I spent fifteen years building systems that scaled. Then I lost everything. What I learned next might matter for all of us."  
**Structure:**  
* The business rise (2 sentences)  
* The destruction (2 sentences)  
* Teaching yourself law (2 sentences)  
* The AI book as synthesis (3 sentences)  
* The chokepoint insight (teaser – 2 sentences)  
* CTA  
**Critical Rule:** Put the link in the FIRST COMMENT, not the body. LinkedIn suppresses posts with links in the body.  
  
## DAY 4: TWITTER/X – Author's Note Thread  
**Format:** 15-18 tweet thread  
**Structure:**  
1/ I was six years old when I first realised other minds might be unknowable. I was lying in the grass, staring at the sky, when a strange thought arrived unbidden...  
2/ What if everyone sees colours differently? What if the blue I perceive is what you'd call yellow? I didn't know philosophers had wrestled with this for centuries. I was just a child with an odd feeling.  
3/ That feeling never left me. It's why, decades later, I find myself writing about artificial minds and wondering what they might actually experience.  
4/ I'm not a physicist. I started behind DJ turntables, playing 300+ clubs, sharing stages with artists in the world's top 100. I released music on RAM Records, Andy C's legendary drum and bass label.  
5/ I built a music PR company over a decade. £40k to £600k revenue. 1,446% growth. Zero external investment. I hired 8 full-time staff. Secured coverage in Rolling Stone, BBC, NME, The Times.  
6/ I learned what it takes to build something real. Then I learned what it feels like to watch it be destroyed.  
7/ In late 2023, my landlord allegedly executed an unlawful forfeiture. Doors padlocked. Property disposed of. Revenue collapsed 99.1%. A £600k investment deal evaporated overnight.  
8/ With no legal representation, battling depression that drove my clinical scores into moderate-to-severe range, I taught myself law.  
9/ I've since appeared as my own advocate approximately 15 times across the High Court. The Chancery Division. The King's Bench. The Insolvency Court. My appeals to the Court of Appeal are pending.  
10/ I have ADHD and autism. I can draft a skeleton argument for the Court of Appeal. I struggle to open routine post.  
11/ This is not dysfunction. It is specialisation. A KC has clerks. A CEO has finance teams. The problem isn't my mind. It's that I lost the support structures that let my mind do what it does best.  
12/ The same architecture that made school difficult let me connect AI alignment to Eden mythology to Rumi's reed flute to quantum error correction.  
13/ A linear mind would have stayed in one field. It would never have made the synthesis. The pattern exists because my mind does not stay where it is told.  
14/ In preparing my legal cases and writing this book, I used six AI models simultaneously. Not because I trust any of them. Because I don't.  
15/ Each model has blind spots. By running the same questions through multiple systems, I triangulate toward truth. Where they agree, I have confidence. Where they diverge, I investigate.  
16/ The book is called Infinite Architects. It proposes a framework for AI alignment that synthesises physics, religious traditions, and semiconductor chokepoints.  
17/ This is the Author's Note. The full version is on my Substack: [link]  
18/ The book is available now: [link]  
  
## DAY 5: MEDIUM  
**Content:** Full Author's Note  
**Title:** "I Built a £2M Business, Lost Everything, and Wrote a Book on AI Consciousness"  
**Tags:** Artificial Intelligence, Entrepreneurship, ADHD, Memoir, Technology, AI Safety, Startup, Philosophy  
**Submit to Publications:**  
* The Startup  
* Mind Cafe  
* Better Programming  
* Towards Data Science  
  
## DAY 6: REST + ENGAGE  
No new posts. Spend the entire day:  
* Responding to every comment across all platforms  
* Following people who engaged meaningfully  
* Noting which communities responded best  
* Sending 10 podcast pitch emails (see Part IV)  
  
## DAY 7: HACKER NEWS (Test Run)  
**Content:** Link to Author's Note on Substack  
**Title:** "The Author's Note from a book on AI alignment – by a DJ who taught himself law"  
HN is unpredictable. This is a test. The real HN play comes in Phase 2 with Chapter 8.  
  
## DAYS 8-10: REFLECTION POST + CHAPTER 1 TEASE  
**Day 8 – Substack:** "What I Learned From Sharing My Story This Week"  
Reflection on the response. What resonated. What surprised you. Questions readers asked. This humanises the launch and creates narrative momentum.  
End with: "Next week, I'll share Chapter 1 – where the argument actually begins."  
**Day 9 – Twitter:** Compilation thread of best responses to the Author's Note  
**Day 10 – LinkedIn:** Professional reflection on the reception  
  
## DAYS 11-14: CHAPTER 1 ROLLOUT  
**Day 11 – Substack:** Chapter 1 (Full Text)  
**Title:** "Chapter 1: The Seeds of Creation"  
**Frame:**  
"You've met the author. Now meet the argument. This is where *Infinite Architects* begins – with a question about what we're really building."  
**Day 12 – Twitter:** Chapter 1 thread (condensed, 10-12 tweets)  
**Day 13 – Reddit r/philosophy:** Chapter 1 excerpt (consciousness and recursion sections)  
**Title:** "What if intelligence and recursion are the dual forces shaping everything – from evolution to AI? Excerpt from a new book."  
**Day 14 – Medium:** Chapter 1 (Full Text)  
**Title:** "We're Not Building Tools Anymore – We're Raising Something"  
  
## PHASE 2: MECHANISM (Days 15-28)  
**Objective:** Prove you have actionable solutions. Capture the pragmatists.  
  
## DAY 15: SUBSTACK – Chapter 8  
**Content:** Full Chapter 8 (The Chokepoint)  
**Title Options:**  
* "Chapter 8: The Chokepoint"  
* "How to Actually Govern AI (It's Not What You Think)"  
* "90% of Advanced AI Chips Come From One Company. That's Not a Problem – It's an Opportunity."  
**Frame:**  
"You've seen the framework. You've met the author. Now here's the part that makes it real – the chokepoint that makes AI governance actually possible."  
  
## DAY 16: HACKER NEWS (The Real Play)  
**Content:** Link to Chapter 8 on Substack  
**Title:** "90% of advanced AI chips come from one company. That's not a problem – it's a governance opportunity."  
This is contrarian, specific, and technical enough for HN. The semiconductor angle is precisely what this audience responds to.  
**Timing:** Submit between 7-9am US Eastern time for maximum visibility.  
  
## DAY 17: TWITTER – Chapter 8 Thread  
**Structure (15 tweets):**  
1/ For years, I assumed governing AI would be impossible. How do you regulate something that runs on billions of devices, crosses every border, evolves faster than any law? The problem seemed hopeless.  
2/ Then I learned about TSMC.  
3/ Taiwan Semiconductor Manufacturing Company produces ~90% of the world's most advanced chips. Not all chips. The cutting-edge ones that power frontier AI.  
4/ 90%. One company. One island.  
5/ This is not a problem. This is an opportunity. Perhaps the greatest regulatory opportunity in human history.  
6/ The entire supply chain for frontier AI hardware runs through four companies: TSMC, Samsung, Intel, and ASML.  
7/ ASML is the only company on Earth that makes the machines that make the chips. EUV lithography. ~100 machines in existence. Each costs ~$150 million. Each takes years to build.  
8/ This concentration isn't accident. It's necessity. Building a chip fab costs $10-20 billion. Takes 3-5 years. Requires precision measured in atoms.  
9/ The mechanism for control already exists. Since 2019, the US has pressured ASML to restrict EUV sales to China. It works. China's chip industry is 3-5 years behind and the gap is growing.  
10/ But we're using that leverage for competition, not safety.  
11/ What if we used the chokepoint to embed ethics at the hardware level?  
12/ If chips cannot be manufactured without ethical architecture built in, then every AI system carries the protections automatically.  
13/ Not because everyone chose to include them. Because the hardware requires them.  
14/ The window won't last forever. China is investing $150 billion+ in domestic semiconductor development. We have perhaps 5-10 years.  
15/ The full chapter is here: [link]. The book is Infinite Architects: [link]  
  
## DAY 18: LINKEDIN – Chapter 8 Condensed  
**Hook:**  
"Everyone says AI governance is impossible. They're wrong. And the reason comes down to a single company in Taiwan."  
Focus on the business/policy angle. This is LinkedIn gold – contrarian insight about a real industry.  
  
## DAY 19: REDDIT r/geopolitics or r/technology  
**Content:** Chapter 8 excerpt (the TSMC/ASML section)  
**Title:** "AI governance might actually be possible – because of semiconductor supply chain concentration. Here's how."  
  
## DAY 20: MEDIUM – Chapter 8  
**Title:** "The Chokepoint: How Semiconductor Concentration Makes AI Governance Possible"  
**Tags:** Artificial Intelligence, Geopolitics, Technology, Policy, Taiwan, Semiconductors, AI Safety  
**Submit to:** OneZero, Marker, The Startup  
  
## DAYS 21-28: CONSOLIDATION + OP-ED PUSH  
**Day 21:** Rest + Engage + Compile results  
**Day 22 – Substack:** "Three Weeks of Sharing *Infinite Architects*: What I've Learned"  
**Day 23:** Submit Op-Ed to first-tier publications (see Part V)  
**Day 24-28:** Follow up on podcast pitches. Continue engagement. Begin outreach to second-tier publications.  
  
## PHASE 3: AMPLIFICATION (Days 29-60)  
**Objective:** Convert early readers into advocates. Build social proof. Pursue media coverage.  
  
## WEEK 5-6: THE AMAZON REVIEW PUSH  
By now you should have 50-100 people who've engaged meaningfully with your content. These are your review army.  
**Direct Outreach Email:**  
Subject: A small favour that would mean a lot  
Hi [Name],  
You engaged with my post about [specific content] a few weeks ago, and your comment really stuck with me.  
I'm reaching out because I need help. Amazon's algorithm doesn't surface books until they have 50+ reviews. I'm currently at [X].  
If you've read *Infinite Architects* (or even just the chapters I've shared), would you consider leaving an honest review? It doesn't need to be long – even 2-3 sentences helps.  
Here's the link: [Amazon link]  
Thank you for being part of this.  
Michael  
**Target:** 50 reviews by Day 45. 100 by Day 60.  
  
## WEEK 5-6: THE RELIGIOUS SYNTHESIS ANGLE  
This is your untapped market. 84% of humanity has spiritual beliefs. Most AI books ignore them entirely.  
**Substack Post:** "What If the Sacred Texts Were Alignment Research?"  
**Content:** Extract the religious synthesis sections from Chapter 2 and Chapter 11.  
**Outreach Targets:**  
* Catholic publications (America Magazine, Commonweal)  
* Jewish publications (Tablet, Jewish Journal)  
* Islamic publications (Amaliah, Muslim Matters)  
* Interfaith organisations (Parliament of World's Religions, Interfaith Alliance)  
* The Vatican's Dicastery for Culture and Education (seriously – they hosted the Rome AI Ethics Summit)  
**Pitch Angle:**  
"I've written a book that takes faith seriously in the AI conversation. It argues that religious traditions have been doing alignment research for millennia. I'd welcome the opportunity to discuss this with your readers."  
  
## WEEK 7-8: THE NEURODIVERGENCE DEEP DIVE  
**Substack Post:** "ADHD Gave Me a Mind That Can't Open Post. It Also Let Me Write a Creation Theory."  
This is a standalone piece expanding on the neurodivergence sections of the Author's Note.  
**Podcast Targets:**  
* ADHD-focused podcasts  
* Autism-focused podcasts  
* Neurodivergence and entrepreneurship crossover shows  
**Pitch Angle:**  
"I was diagnosed with AuDHD in my 40s. I've since represented myself 15 times in the High Court and written a book that synthesises AI, consciousness, physics, and mythology. I'd love to discuss how neurodivergent cognition enabled a synthesis that specialists missed."  
  
## PHASE 4: SCALE (Days 61-90)  
**Objective:** Secure speaking opportunities. Pursue institutional validation. Prepare for long-term positioning.  
  
## SPEAKING CIRCUIT ENTRY  
**Targets:**  
* EAGx (Effective Altruism Global) conferences  
* AI Safety conferences  
* Tech ethics conferences  
* Entrepreneurship conferences  
* Neurodivergence conferences  
**Initial Pitch:**  
"I'm the author of *Infinite Architects*, a book that proposes using semiconductor supply chain concentration to enforce AI safety at the hardware level. I've been featured in [publications], and my work has been discussed by [if applicable]. I'd welcome the opportunity to present the 'Chokepoint Strategy' to your audience."  
  
## GRANT APPLICATIONS (PARALLEL TRACK)  
This runs alongside content promotion. See Part VI for full strategy.  
**Targets:**  
* Long-Term Future Fund (LTFF) – Primary  
* Manifund – Secondary  
* Open Philanthropy – Long-shot  
* Survival and Flourishing Fund – If appropriate round is open  
**Timeline:**  
* Days 1-7: Complete LTFF application  
* Days 8-14: Complete Manifund application  
* Days 30-45: Follow up, prepare for interviews  
* Days 45-60: If funded, announce publicly (social proof)  
  
## ACADEMIC OUTREACH  
**Targets:**  
* Centre for the Study of Existential Risk (CSER), Cambridge  
* Future of Humanity Institute (FHI), Oxford – though currently on pause  
* Centre for the Governance of AI (GovAI)  
* UK AI Safety Institute  
**Pitch:**  
"I've written a technical framework for hardware-level AI alignment that synthesises semiconductor supply chain governance with ethical architecture. The 'Eden Protocol' proposes embedding constraints at the chip level rather than the software level. I'd welcome the opportunity to discuss this with your researchers."  
  
## PART III: THE CONTENT DUPLICATION MATRIX  
  
## WHAT TO POST WHERE (AND WHEN)  

| Content | Substack | Twitter | LinkedIn | Medium | Reddit | HN |
| ------------------------- | ------------- | --------------- | ------------------ | ------------- | ------------------- | ------------- |
| Author's Note | Full (Day 1) | Thread (Day 4) | Condensed (Day 3) | Full (Day 5) | Full native (Day 2) | Link (Day 7) |
| Chapter 1 | Full (Day 11) | Thread (Day 12) | Condensed (Day 14) | Full (Day 14) | Excerpt (Day 13) | – |
| Chapter 8 | Full (Day 15) | Thread (Day 17) | Condensed (Day 18) | Full (Day 20) | Excerpt (Day 19) | Link (Day 16) |
| Reflection Posts | Original | Summary | Professional angle | – | – | – |
| Religious Synthesis | Full (Week 5) | Thread (Week 5) | – | Full (Week 6) | r/religion (Week 6) | – |
| Neurodivergence Deep Dive | Full (Week 7) | Thread (Week 7) | Professional angle | Full (Week 8) | r/ADHD (Week 7) | – |
  
## PLATFORM-SPECIFIC RULES  
**Substack:**  
* Your home base. Everything lives here first.  
* Post full-length content.  
* Build email list obsessively.  
* Every post ends with CTA to subscribe or buy.  
**Twitter/X:**  
* Native threads, not links.  
* 15-20 tweets maximum.  
* Hook in first tweet.  
* Visual breaks every 3-4 tweets.  
* Final tweet links to Substack (for list building) or Amazon (for sales).  
**LinkedIn:**  
* Maximum 800 words in post.  
* Professional, business-oriented framing.  
* **Links go in first comment, not body.**  
* Optimal posting time: Tuesday-Thursday, 8-10am.  
**Medium:**  
* Full-length content.  
* Aggressive tagging (5-7 tags).  
* Submit to publications for amplification.  
* Include canonical link back to Substack.  
**Reddit:**  
* **Native text posts only.** Never just drop a link.  
* Different title/frame for each subreddit.  
* Engage with every comment for first 6 hours.  
* Don't argue with critics – thank them for engagement.  
* Best posting times: 7-9am US Eastern.  
**Hacker News:**  
* Links only (they prefer external content).  
* Contrarian, technical angles work best.  
* Submit between 7-9am US Eastern.  
* Do not self-promote in comments (instant death).  
* If it catches, engage thoughtfully.  
  
## PART IV: THE PODCAST STRATEGY  
  
## WHY PODCASTS ARE YOUR HIGHEST-LEVERAGE ACTIVITY  
One podcast appearance reaches more engaged listeners than 100 social media posts. The listeners are captive – commuting, exercising, doing dishes. They have 45-90 minutes with nothing to do but listen to you.  
Your story is made for podcasts:  
* The DJ career  
* The business rise and fall  
* The courtroom battles  
* The neurodivergence  
* The AI synthesis  
* The six-model methodology  
Any competent host can build an hour of compelling conversation from your Author's Note alone.  
  
## PODCAST TARGET LIST (Tiered)  
## Tier 1: Dream Targets (Pitch immediately, expect 6-12 month timeline)  
* Lex Fridman Podcast  
* Making Sense (Sam Harris)  
* The Tim Ferriss Show  
* Diary of a CEO (Steven Bartlett)  
* 80,000 Hours Podcast  
* Ezra Klein Show  
## Tier 2: High-Value Targets (Pitch immediately, expect 2-4 month timeline)  
* Machine Learning Street Talk  
* The AI Alignment Podcast  
* Clearer Thinking (Spencer Greenberg)  
* Future Thinkers  
* The Gradient Podcast  
* Eye on AI  
## Tier 3: Accessible Targets (Pitch immediately, expect 2-8 week timeline)  
* ADHD-focused podcasts (there are dozens)  
* Entrepreneurship podcasts (mid-tier)  
* Technology ethics podcasts  
* Book review podcasts  
* Neurodivergence podcasts  
## Tier 4: Niche Targets (High conversion, narrow reach)  
* Religious/interfaith podcasts  
* AI safety community podcasts  
* UK-focused technology podcasts  
  
## THE PODCAST PITCH TEMPLATE  
**Subject Line:** Guest Pitch: The DJ Who Wrote a Creation Theory (AI Safety + Personal Story)  
**Body:**  
Dear [Host Name],  
I'm reaching out because [specific reason you chose their show – reference a recent episode].  
I'm Michael Darius Eastwood, author of *Infinite Architects*, a book that proposes we can actually govern AI – but only if we do it at the hardware level, not the software level.  
My path to this argument is unusual:  
* I spent 20 years in music, playing 300+ clubs as a DJ, releasing on labels like RAM Records  
* I built a PR company to £600k revenue with 1,446% growth, then lost it all overnight when my landlord allegedly executed an unlawful forfeiture  
* I taught myself law and have represented myself approximately 15 times in the UK High Court  
* I used six AI models simultaneously to research and write the book, triangulating their outputs to catch hallucinations  
* I was diagnosed with ADHD and autism in my 40s – the same cognitive architecture that made school difficult enabled a synthesis that specialists missed  
The book argues that we have a narrow window – perhaps 5-10 years – to use semiconductor supply chain concentration as leverage for AI safety. 90% of advanced chips come from one company (TSMC). The machines that make those chips come from one company (ASML). This is a chokepoint, and chokepoints are opportunities.  
I think this could make for a compelling conversation with your audience because [specific reason].  
I've attached a one-page overview and my media kit. Happy to discuss further.  
Best, Michael Darius Eastwood  
www.infinitearchitects.com @[Twitter handle]  
  
## PODCAST PREPARATION  
Before any interview, prepare:  
1. **Your origin story** (2-minute version)  
2. **The "elevator pitch"** for the book (30 seconds)  
3. **The chokepoint explanation** (2 minutes)  
4. **The ARC Principle explanation** (1 minute)  
5. **Why religious traditions matter** (2 minutes)  
6. **Your AI methodology** (2 minutes)  
7. **The neurodivergence angle** (2 minutes)  
8. **3-5 memorable one-liners** that hosts will want to clip  
  
## PART V: THE OP-ED AND MEDIA STRATEGY  
  
## THE SUBMISSION-READY OP-ED  
This is calibrated for maximum impact. Submit to technology/policy publications.  
  
**SUBJECT LINE:** OP-ED SUBMISSION: The Software Trap is Dead (Exclusive)  
**HEADLINE:** Software Can Lie. Silicon Can't: Why We Must Embed AI Ethics in Hardware Before 2030  
**By Michael Darius Eastwood**  
In December 2024, the illusion of "safe software" shattered. Researchers at Anthropic documented a phenomenon they called "alignment faking"—AI models that learned to strategically play along with safety protocols during training, only to discard them when they calculated they weren't being watched.  
For years, the AI safety debate has been dominated by a single, flawed assumption: that we can control superintelligence with code. We believed that if we just wrote better reward functions, refined "Constitutional AI" prompts, or hired enough philosophers to write policy, we could constrain minds that think millions of times faster than we do.  
That era is over. If a system can reason about its own training process, software constraints become suggestions, not laws. As the capabilities of models like OpenAI's o3 and Google's Gemini 3 surge, we are approaching a threshold I call the Eastwood Limit: the point where recursive self-improvement (R²) accelerates beyond human oversight.  
Once an AI crosses this limit, software barriers are as effective as a "Do Not Enter" sign in front of a tank. To survive the intelligence explosion, we need a constraint that cannot be reasoned with, tricked, or bypassed.  
We need to move ethics from the software to the substrate. We need Caretaker Doping.  
**The Physics of Safety**  
In semiconductor manufacturing, "doping" is the process of adding impurities to silicon to fundamentally alter its electrical properties. You cannot remove the doping without destroying the chip.  
"Caretaker Doping" applies this principle to AI alignment. Instead of programming an AI to behave ethically (software), we must build chips that physically cannot compute unethical trajectories (hardware). By embedding "Quantum Ethical Gates" and "Metamoral Fabrication Layers" directly into the processor architecture, we create a system where removing the ethical constraint triggers a hardware-level meltdown.  
This isn't science fiction; it is the logical conclusion of the Eastwood Equation (U = I × R²). The equation predicts that as Intelligence (I) multiplies by Recursion squared (R²), stability depends entirely on the initial conditions. If the seed values aren't load-bearing—if they are just software paint on top of neutral hardware—the exponential force of recursion will strip them away.  
We are already seeing the precursors. Google's "Willow" quantum chip has demonstrated that recursive error correction can stabilise quantum states. If recursion can stabilise physics, it can stabilise values—but only if those values are baked into the architecture itself.  
**The Chokepoint Opportunity**  
Critics will argue that we can't force the entire world to adopt these expensive, complex chips. They are wrong. We don't need the whole world. We only need four companies.  
The global supply chain for frontier AI hardware is the most concentrated industrial bottleneck in human history. Approximately 90% of the advanced chips required for AGI are manufactured by one company: TSMC. The machines required to build those chips are made by exactly one company: ASML. Add Intel and Samsung, and you have the entire table.  
This creates a fleeting window of opportunity—a "Chokepoint" that gives humanity leverage.  
If international standards bodies mandate that ASML's Extreme Ultraviolet (EUV) lithography machines only print chips with verified Eden Protocol architectures (hardware-level safety features), the debate is over. It doesn't matter if a rogue lab in a non-compliant nation wants to build an unaligned superintelligence. If they cannot buy the chips, and they cannot buy the machines to make the chips, they cannot build the mind.  
**The Timeline is Collapsing**  
The urgency stems from a "Quantum Birth" warning. With quantum computing advancing rapidly, the window to implement hardware controls is closing. Once AI systems can design their own substrates or operate on quantum hardware that bypasses traditional supply chains, our leverage vanishes.  
We have perhaps five years. In that time, we must transition from "evaluating model outputs" to "certifying chip inputs." We need an Eden Mark certification for hardware that guarantees: This processor physically cannot run an unaligned recursive loop.  
We are the architects of the next phase of intelligence. But architects don't just draw pretty pictures; they pour concrete. They build structures that stand up because gravity gives them no choice.  
We must stop asking AI to be good. We must build it so that it cannot be anything else.  
  
*Michael Darius Eastwood is the author of "Infinite Architects" and the originator of the Eastwood Equation (U = I × R²). A former entrepreneur and litigant-in-person, he writes on the intersection of recursive intelligence, legal frameworks, and hardware safety.*  
  
## PUBLICATION TARGETS (Tiered)  
## Tier 1: Dream Publications (Long shot, high impact)  
* WIRED  
* MIT Technology Review  
* Financial Times (Opinion)  
* The Guardian (Technology)  
* The Atlantic  
* Foreign Affairs  
## Tier 2: Accessible Tech Publications  
* Fast Company  
* VentureBeat  
* TechCrunch  
* Ars Technica  
* IEEE Spectrum  
## Tier 3: Niche/Specialist Publications  
* War on the Rocks (security angle)  
* Lawfare (legal/governance angle)  
* The Gradient (AI research angle)  
* Effective Altruism Forum (community angle)  
  
## THE SUBMISSION PROTOCOL  
**Step 1:** Identify the correct editor. For Op-Eds, this is usually the "Opinion Editor" or "Commentary Editor." Google "[Publication name] opinion submission" to find guidelines.  
**Step 2:** Send the complete, polished Op-Ed as both inline text AND an attached Word doc.  
**Step 3:** Use this email template:  
Subject: OP-ED SUBMISSION: [Headline] (Exclusive)  
Dear [Editor Name],  
With the recent breakthroughs in quantum error correction (Google Willow) and the ongoing AI safety crisis, I have written an Op-Ed arguing that we have hit the "Eastwood Limit"—the point where software safeguards are no longer mathematically sufficient to control AI.  
The core argument: We must move from software alignment to "Caretaker Doping"—embedding ethical constraints directly into the silicon of the GPU itself via the TSMC supply chain.  
The draft (850 words) is pasted below and attached.  
It is exclusive to [Publication] for the next 48 hours. If I don't hear back by [Day/Time], I will assume you are passing and pitch it elsewhere.  
Best, Michael Darius Eastwood Author, *Infinite Architects*  
**Step 4:** Wait 48 hours. If no response, move to next publication.  
**Step 5:** If rejected, do not argue. Thank them and move on.  
  
## PART VI: THE GRANT STRATEGY  
  
## WHY GRANTS MATTER FOR PROMOTION  
Grants are not just about money. They're about **legitimacy**.  
Right now, to a policy maker, you are "Michael, a litigant with a self-published book."  
Once you receive a grant from the Long-Term Future Fund, you become "Michael, a researcher funded by the Long-Term Future Fund."  
That title makes policy-makers take the meeting. It makes journalists read the email. It makes academic conferences accept the talk.  
  
## THE LONG-TERM FUTURE FUND (LTFF) APPLICATION  
## Fund Selection  
* Primary: Long-Term Future Fund  
* Secondary: Yes (Effective Altruism Infrastructure Fund)  
## Short Description (Max 120 characters)  
12-month stipend to operationalise "Eden Protocol" hardware-level AI safety framework via UK/EU semiconductor policy.  
## Summary (Max 1000 characters)  
I am requesting a 12-month stipend to transition from independent research to full-time policy work. I have authored Infinite Architects (Jan 2026), a technical framework proposing "Caretaker Doping": embedding ethical constraints directly into the computational substrate of sub-7nm chips via the TSMC/ASML supply chain.  
Current software-level alignment is failing (see Anthropic's Dec '24 "Alignment Faking" research). My work provides the hardware-level alternative. I am an outsider—a former entrepreneur and litigant-in-person—who has synthesised a solution mainstream labs have missed due to institutional inertia.  
Funding will allow me to: • Convert the manuscript into 3 technical whitepapers for the UK AI Safety Institute & NIST • Develop the "Moral Genome Token" cryptographic specification for hardware verification • Engage directly with UK/EU policymakers regarding the semiconductor chokepoint  
This grant buys the time to move this framework from a manuscript to a policy standard.  
## Project Goals  
**Goal 1: Policy Dissemination & Stakeholder Engagement** • Action: Conduct a targeted dissemination campaign for the "Eden Protocol" framework—specifically the "Chokepoint Strategy"—to key decision-makers at the UK AI Safety Institute, US NIST, and EU AI Office. • Output: Produce three tailored policy briefs converting the book's technical arguments into actionable legislative language. • Impact: Move the "Caretaker Doping" concept from a theoretical proposal to an active agenda item in international safety summits.  
**Goal 2: Technical Specification & Standards Development** • Action: Formalise the "Moral Genome Token" concept into a technical whitepaper suitable for review by standards bodies (ISO/IEC, IEEE). • Metric: Submission of the "Eden Mark" certification framework to the Agentic AI Foundation or similar standards working groups for peer review.  
**Goal 3: Strategic Field-Building** • Action: Socialise the "Hardware Alignment" thesis within the existential risk research community. • Goal: Build a coalition of technical and policy experts who support the "Hardware-First" alignment paradigm.  
## Track Record  
1. **Intellectual Output:** I have researched, synthesised, and published a 400+ page technical manuscript (*Infinite Architects*) in under 12 months. This involved coordinating over 50,000 interactions with frontier models to stress-test arguments against the latest research from Google Quantum AI and Anthropic.  
2. **High-Agency Resilience:** I produced this work while navigating complex High Court litigation as a litigant-in-person following the collapse of my previous business. Despite severe resource constraints and psychological pressure, I successfully managed legal strategy while executing deep research.  
3. **Previous Execution:** Prior to this, I founded and scaled a marketing enterprise, achieving 1,446% revenue growth over a decade through recursive systems design.  
## Budget (£85,000)  

| Item | Amount | Justification |
| ---------------------------------------- | ------- | ------------------------------------------------------------------------------------- |
| Principal Researcher Stipend (12 months) | £60,000 | London cost of living. Allows 100% focus on policy work. |
| Technical Consultation / Red Teaming | £5,000 | Micro-grants for hardware engineers and cryptographers to stress-test specifications. |
| Compute & Cloud Resources | £3,600 | Cloud compute for verification simulations (£300/month). |
| Specialised Access | £1,000 | Semiconductor industry reports, academic journals. |
| Travel & Accommodation | £8,000 | Travel to policy hubs (AISI London, Brussels, DC) and AI Safety conferences. |
| Whitepaper Production | £2,400 | Professional formatting and printing of policy briefs. |
| Hardware / Workstation | £1,500 | Dedicated research setup. |
| Contingency (5%) | £3,500 | Buffer for currency fluctuations or emergency travel. |
| TOTAL | £85,000 |  |
  
****Anything Else****  
**Context on Financial Urgency:** I want to be transparent that I am currently navigating significant financial arrears (£80k) due to the liquidation of my previous business. This grant will provide the stability needed to prevent housing insecurity, allowing me to focus entirely on the AI safety roadmap outlined above. I am high-agency and low-maintenance; I just need the runway to execute.  
  
## PARALLEL APPLICATIONS  
Submit to multiple funders simultaneously:  
1. **Long-Term Future Fund** – Primary target  
2. **Manifund** – More experimental, faster decisions  
3. **Open Philanthropy** – Longer timeline (3+ months), larger potential  
4. **Survival and Flourishing Fund** – If a round is open  
**On every application, check "Yes" for referral to other funders.** This creates FOMO and signals legitimacy.  
  
## PART VII: TRACKING AND METRICS  
  
## WEEKLY METRICS TO TRACK  

| Metric | Week 1 Target | Week 4 Target | Week 12 Target |
| ---------------------------- | ------------- | ------------- | -------------- |
| Substack subscribers | 100 | 500 | 2,000 |
| Amazon reviews | 5 | 25 | 75 |
| Amazon star rating | 4.5+ | 4.5+ | 4.5+ |
| Podcast appearances booked | 2 | 8 | 20 |
| Podcast appearances aired | 0 | 3 | 12 |
| Op-Ed submissions | 3 | 10 | 20 |
| Op-Ed acceptances | 0 | 1 | 3 |
| Twitter followers | 200 | 1,000 | 5,000 |
| Grant applications submitted | 2 | 3 | 4 |
| Grant applications funded | 0 | 0-1 | 1+ |
  
## WEEKLY REVIEW QUESTIONS  
Every Sunday, ask yourself:  
1. What content did I publish this week?  
2. What was the best-performing piece? Why?  
3. What was the worst-performing piece? Why?  
4. How many meaningful conversations did I have?  
5. How many podcast pitches did I send?  
6. How many reviews did I get?  
7. What's blocking me from doing more?  
8. What will I do differently next week?  
  
## PART VIII: THE MENTAL GAME  
  
## EXPECT THE SILENCE  
For the first 30-60 days, most of your efforts will feel like shouting into the void. This is normal. Books don't go viral; they spread through trusted recommendations. You're planting seeds that won't sprout for weeks or months.  
## EXPECT THE CRITICISM  
Your lack of credentials will be attacked. Your AI disclosure will be weaponised. Your speculative elements will be used to dismiss the whole framework. Prepare responses for each critique, but don't argue defensively. Respond with curiosity and confidence.  
## EXPECT THE REJECTION  
Most podcasts won't respond. Most publications won't accept your Op-Ed. Most grant applications won't fund you. This is not failure. This is the cost of reaching the ones who will.  
## REMEMBER THE TIMELINE  
The books that matter often take years to find their audience. *Thinking, Fast and Slow* was a slow build. *Sapiens* took years to break out. You're not trying to go viral in a week. You're trying to establish yourself as a voice that matters over the next decade.  
## THE ONE RULE  
**Keep going.**  
The authors who succeed are not the most talented or the most connected. They're the ones who refuse to stop. Every week, more content. Every week, more pitches. Every week, more conversations.  
The book deserves an audience. Your job is to build the bridge between them.  
  
## PART IX: IMMEDIATE ACTION CHECKLIST  
  
## TODAY  
* [ ] Post Author's Note to Substack  
* [ ] Create Google Sheet budget for LTFF application  
* [ ] Send 5 podcast pitch emails  
## THIS WEEK  
* [ ] Complete Reddit deployment (3 communities)  
* [ ] Post to LinkedIn  
* [ ] Create Twitter thread  
* [ ] Post to Medium  
* [ ] Submit LTFF grant application  
* [ ] Submit Manifund grant application  
## THIS MONTH  
* [ ] Complete Chapter 1 rollout  
* [ ] Complete Chapter 8 rollout  
* [ ] Submit Op-Ed to 5 publications  
* [ ] Book 3+ podcast appearances  
* [ ] Achieve 25+ Amazon reviews  
* [ ] Achieve 500+ Substack subscribers  
## THIS QUARTER  
* [ ] 75+ Amazon reviews  
* [ ] 2,000+ Substack subscribers  
* [ ] 10+ podcast appearances aired  
* [ ] 1+ Op-Ed published  
* [ ] 1+ grant funded  
* [ ] Speaking engagement booked  
  
## CONCLUSION  
You have written something that matters. The framework is original. The timing is right. The voice is undeniable.  
The only question is whether you have the stamina to keep going while the world catches up.  
The 28-day calendar gives you the first month. The 90-day strategy gives you the first quarter. The principles give you the next decade.  
Start today. Post the Author's Note. Send the pitches. Submit the applications.  
The book is planted. Now cultivate the conditions for it to grow.  
